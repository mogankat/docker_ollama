services:
  nginx-lb:
    image: nginx:latest
    container_name: nginx-lb
    ports:
      - "8081:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - mistral
      - llama3
      - gemma3
      - deepseek
      - qwen3
      - qwen3-coder

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    environment:
      - OLLAMA_BASE_URLS=http://nginx-lb/node1/;http://nginx-lb/node2/;http://nginx-lb/node3/;http://nginx-lb/node4/;http://nginx-lb/node5/;http://nginx-lb/node6/
      - ENABLE_PERSISTENT_CONFIG=False
      - WEBUI_AUTH=False 
      - WEBUI_NAME=I, for One, Welcome Our New AI Overlords
      - CORS_ALLOW_ORIGIN=*
    volumes:
      - open-webui:/app/backend/data
    restart: always

  mistral:
    image: ollama/ollama:latest
    container_name: ollama-mistral
    volumes: ["ollama_storage_1:/root/.ollama"]
    restart: unless-stopped

  llama3:
    image: ollama/ollama:latest
    container_name: ollama-llama3
    volumes: ["ollama_storage_2:/root/.ollama"]
    restart: unless-stopped

  gemma3:
    image: ollama/ollama:latest
    container_name: ollama-gemma3
    volumes: ["ollama_storage_3:/root/.ollama"]
    restart: unless-stopped

  deepseek:
    image: ollama/ollama:latest
    container_name: ollama-deepseek
    volumes: ["ollama_storage_4:/root/.ollama"]
    restart: unless-stopped

  qwen3:
    image: ollama/ollama:latest
    container_name: ollama-qwen3
    volumes: ["ollama_storage_5:/root/.ollama"]
    restart: unless-stopped

  qwen3-coder:
    image: ollama/ollama:latest
    container_name: ollama-qwen3-coder
    volumes: ["ollama_storage_6:/root/.ollama"]
    restart: unless-stopped

  model-importer:
    image: ollama/ollama:latest
    entrypoint: /bin/sh
    command: >
      -c "sleep 10;
      OLLAMA_HOST=mistral:11434 ollama pull mistral:latest &&
      OLLAMA_HOST=llama3:11434 ollama pull llama3.1:latest &&
      OLLAMA_HOST=gemma3:11434 ollama pull gemma3:latest &&
      OLLAMA_HOST=deepseek:11434 ollama pull deepseek-r1:latest &&
      OLLAMA_HOST=qwen3:11434 ollama pull qwen3:latest &&
      OLLAMA_HOST=qwen3-coder:11434 ollama pull qwen3-coder:latest"
    depends_on:
      - mistral
      - llama3
      - gemma3
      - deepseek
      - qwen3
      - qwen3-coder

  dozzle:
    image: amir20/dozzle:latest
    container_name: log-viewer
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    ports:
      - "8888:8080"
    restart: unless-stopped

volumes:
  open-webui:
  ollama_storage_1:
  ollama_storage_2:
  ollama_storage_3:
  ollama_storage_4:
  ollama_storage_5:
  ollama_storage_6: